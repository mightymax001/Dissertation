{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b00b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_json('tweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92103b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweeted'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = data_df[['internal_id', 'retweeted', 'in_reply_to_user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df1['in_reply_to_user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = nx.from_pandas_edgelist(data_df, source = \"id\", target = \"in_reply_to_user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c45a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51830bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3726ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa395854",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = pd.read_json(\"tweet_user_relationship.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b587a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df = pd.read_json(\"mentions.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524edd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df.rename(columns = {'user_id' : 'OG_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df.rename(columns = {'user_id' : 'mention_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4598971",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_merge = pd.merge(mentions_df,relationship_df,left_on=mentions_df['tweet_id'],right_on=relationship_df['tweet_id'])\n",
    "\n",
    "mentions_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb165284",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = nx.from_pandas_edgelist(mentions_merge, source = \"mention_id\", target = \"OG_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,50) )\n",
    "nx.draw(graph2, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cea597",
   "metadata": {},
   "source": [
    "# Exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08538dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_json('tweets.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba219bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820575ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4044b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tweets['lang'].value_counts()\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"lang\", data = tweets)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11804b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweeted_id'].isnull().sum()\n",
    "\n",
    "#6403/7509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = tweets['retweeted_id']\n",
    "\n",
    "retweets1 = pd.DataFrame(retweets)\n",
    "\n",
    "retweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets1['null']  = retweets1['retweeted_id']\n",
    "\n",
    "retweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed54afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets1['null'] = retweets1['null'].fillna('no retweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ebcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704cd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets1.loc[retweets1['null'] != 'no retweet', 'null'] = 'retweet'\n",
    "\n",
    "retweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets1['null'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- 5061/ 7503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba707bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"null\", data = retweets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbf2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8808964",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "edges = [('V1', 'V2'),\n",
    "         ('V1', 'V5'),\n",
    "         ('V2' ,'V5'),\n",
    "         ('V2', 'V3'),\n",
    "         ('V3', 'V4'),\n",
    "         ('V4', 'V5'),\n",
    "         ('V5', 'V6'),\n",
    "         ('V3', 'V3')\n",
    "         \n",
    "        ]\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "node_options = {'node_color': 'black', 'node_size':30}\n",
    "\n",
    "edge_options = {'width': .50, 'alpha':.5, 'edge_color': 'black'}\n",
    "\n",
    "node_label_options = {'font_size': 15,\n",
    "                     'font_color': 'blue',\n",
    "                     'verticalalignment': 'bottom',\n",
    "                     'horizontalalignment': 'left'}\n",
    "\n",
    "#nx.draw_networkx_nodes(G, pos, **node_options)\n",
    "\n",
    "#nx.draw_networkx_edges(G, pos, **edge_options)\n",
    "\n",
    "#nx.draw_networkx_labels(G, pos, **node_label_options)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, arrowsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "matplotlib.pyplot.arrow(0,0, 2, 2, head_width = 0.1, color = 'r')\n",
    "\n",
    "matplotlib.pyplot.arrow(0,0, 4, 3, head_width = 0.1, color = 'g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a797bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c428e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a16167",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'max has greatly enjoyed working on his dissertation'\n",
    "doc2 = 'max has been working really hard on his dissertation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_doc1 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1.lower()).split()\n",
    "l_doc2 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc2.lower()).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f393e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform([doc1,doc2])\n",
    "df_bow_sklearn = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "df_bow_sklearn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a152d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b81c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed81be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d416c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b6b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e39784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc065435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8881017f",
   "metadata": {},
   "source": [
    "## Text preprocessing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data_df ## need fix this at top of notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_tweets = tweets[['id', 'full_text', 'lang']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "clean_tweets1['clean_text1'] = clean_tweets1['clean_text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb31efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "stop\n",
    "\n",
    "stop.extend(['rt', 'amp', 't', 's'])\n",
    "\n",
    "#stop.extend(extrastop)\n",
    "\n",
    "stop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df):\n",
    "    \n",
    "    df = df.loc[df['lang'] == 'en']\n",
    "    \n",
    "    df = df[['id', 'full_text']]\n",
    "    \n",
    "    df['clean_text'] = df['full_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "    \n",
    "    df['clean_text'] = df['clean_text'].str.lower()\n",
    "    \n",
    "    df = df.drop_duplicates(subset='clean_text', keep = 'first') # might wanna remove this\n",
    "    \n",
    "    def remove_punct(data):\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        return data.translate(table)\n",
    "    \n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: remove_punct(x))\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    #df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    \n",
    "   \n",
    "    \n",
    "    df = df.loc[df['clean_text'] != '']\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7252c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = cleaner(tweets)\n",
    "\n",
    "clean_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd1128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3576e5",
   "metadata": {},
   "source": [
    "## function for making network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79660e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684daa6a",
   "metadata": {},
   "source": [
    "## same thing for all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ede8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = tweets[['id', 'full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ad6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english',\n",
    "                             \n",
    "                             min_df = 3\n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "vectors = vectorizer.fit_transform(tweets1['full_text'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "df_vectors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f24327",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['vectors'] = denselist\n",
    "\n",
    "tweets1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac16da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['key'] = 0\n",
    "\n",
    "\n",
    "\n",
    "tweets1 = tweets1.merge(tweets1, on = \"key\", how = 'outer')\n",
    "\n",
    "tweets1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "for i in tweets1.iterrows():\n",
    "    \n",
    "    sim = 1 - spatial.distance.cosine(i[1][2], i[1][6])\n",
    "    \n",
    "    empty.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62119671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37694512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8864945f",
   "metadata": {},
   "source": [
    "# TFidf and cos similarity with all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = cleaner(tweets)\n",
    "\n",
    "clean_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english',\n",
    "                             \n",
    "                             min_df = 5,\n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             max_df = 0.8\n",
    "\n",
    ")\n",
    "\n",
    "vectors = vectorizer.fit_transform(clean_tweets['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = vectors.todense()\n",
    "\n",
    "print(abc.shape)\n",
    "\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2387f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_df = pd.DataFrame(abc, \n",
    "                       columns = vectorizer.get_feature_names())\n",
    "\n",
    "dense_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame(cosine_similarity(dense_df, dense_output = True))\n",
    "\n",
    "print(sim_df.shape)\n",
    "\n",
    "sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8fef5a",
   "metadata": {},
   "source": [
    "# rjnnernrgtewnjrtewgnrtewjgnrtweigbntwreihbgnthrwibe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cosine_similarity(vectors)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e93d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## be careful to not double run the loop below or there lists get double filled\n",
    "\n",
    "c = clean_tweets['id'].tolist()  ############ error hereeeeeee\n",
    "\n",
    "h = []\n",
    "v = []\n",
    "w = []\n",
    "\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa82467",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    for j in range(a.shape[1]):\n",
    "        #if a[i][j] > 0.15 and a[i][j] < 0.99:\n",
    "        h.append(c[i])\n",
    "        v.append(c[j])\n",
    "        w.append(a[i][j])\n",
    "        \n",
    "        # comment out the i = j bit when getting the plot of num of nodes vs threshold\n",
    "        #if i == j:\n",
    "         #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = pd.DataFrame({'id_x': h, 'id_y': v, 'similarity': w})\n",
    "edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = edge[(edge['similarity'] < 0.99)]\n",
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f011359",
   "metadata": {},
   "outputs": [],
   "source": [
    "115470/35681084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_combinations (df):\n",
    "    \n",
    "    df['key'] = 0\n",
    "    \n",
    "    df = df.merge(df, on = 'key', how = 'outer')\n",
    "    \n",
    "    df = df[['id_x', 'clean_text_x', 'id_y', 'clean_text_y']]\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "    return (df)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce828efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_combs = tweets_combinations(clean_tweets)\n",
    "\n",
    "#tweet_combs['source'] = edge['source']\n",
    "\n",
    "#tweet_combs['target'] = edge['target']\n",
    "\n",
    "tweet_combs['similarity'] = edge['similarity']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaccard_tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48063735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index_grid_search(df):\n",
    "    \n",
    "    # Calculate Jaccard Index and save it in a column\n",
    "    \n",
    "    \n",
    "    # Find number of connections for differenct jaccard index threshold\n",
    "    index_connections = pd.DataFrame(columns = ['jaccard_threshold', 'connections'])\n",
    "    for i in np.arange(0.0, 1.0, 0.01):\n",
    "        df1 = df[tweet_combs['similarity'] >= i]\n",
    "        index_connections = index_connections.append({'jaccard_threshold': i, 'connections': df1.shape[0]}, \n",
    "                                                     ignore_index=True)\n",
    "\n",
    "    return df, index_connections\n",
    "jaccard_tweets, index_connections = jaccard_index_grid_search(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a54cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_connections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a061f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_connections = index_connections['connections'].tolist()\n",
    "\n",
    "connections_per_tweet = [i/(len(tweet_combs)) for i in idx_connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82086020",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = index_connections['jaccard_threshold'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold, connections_per_tweet)\n",
    "\n",
    "plt.xticks(np.arange(0,1, step = 0.05))\n",
    "\n",
    "plt.xlabel('Cosine threshold')\n",
    "\n",
    "plt.ylabel('Connections per node')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e446f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_per_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30254126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.histplot(jaccard_tweets, x = 'similarity', bins = 100)\n",
    "\n",
    "plot.set(xlabel = 'similarity')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def6b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5ddbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372802e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4 = nx.from_pandas_edgelist(edge, source = \"id_x\", target = \"id_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [node for node, degree in graph4.degree() if degree < 5]\n",
    "graph4.remove_nodes_from(remove)\n",
    "pos = nx.spring_layout(graph4, k=0.15, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph4 = nx.from_pandas_edgelist(edge, source = \"source\", target = \"target\")\n",
    "\n",
    "plt.figure(figsize = (50,50) )\n",
    "nx.draw(graph4, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da7649",
   "metadata": {},
   "source": [
    "## community detection for tfidf network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_louvain = algorithms.louvain(graph4, resolution=1., randomize=True)\n",
    "\n",
    "communities = coms_louvain.communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08553b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coms_louvain.communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(0,len(communities)):\n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "    count = count + len(communities[i])\n",
    "    \n",
    "print('Total num of tweets in all communities is :', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = nx.spring_layout(graph4)\n",
    "\n",
    "\n",
    "\n",
    "viz.plot_network_clusters(graph4, coms_louvain, pos, min_size = 8, figsize = (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(graph4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0025937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.newman_girvan_modularity(graph4, coms_louvain))\n",
    "print(evaluation.avg_distance(graph4, coms_louvain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.newman_girvan_modularity(graph4, coms_louvain))\n",
    "print(evaluation.avg_distance(graph4, coms_louvain))\n",
    "print(evaluation.cut_ratio(graph4, coms_louvain))\n",
    "print(evaluation.average_internal_degree(graph4, coms_louvain))\n",
    "print(evaluation.conductance(graph4, coms_louvain))\n",
    "print(evaluation.internal_edge_density(graph4, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a19632",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this method for specifying communities down below for wordcloud generation\n",
    "\n",
    "communities = coms_louvain.communities\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(0,len(communities)):\n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "    count = count + len(communities[i])\n",
    "    \n",
    "print('Total num of tweets in all communities is :', count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffdd2c",
   "metadata": {},
   "source": [
    "## actual method used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c56c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#communities = nx_comm.louvain_communities(graph4, seed=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(0,len(communities)):\n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "    count = count + len(communities[i])\n",
    "    \n",
    "print('Total num of tweets in all communities is :', count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a92601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_generator (num_colors):\n",
    "    \n",
    "    number_of_colors = num_colors\n",
    "    \n",
    "    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "    \n",
    "    return(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_groups = []\n",
    "for com in communities:\n",
    "    node_groups.append(list(com))\n",
    "\n",
    "def color_mapping (communities):\n",
    "    \n",
    "    colors = colour_generator (len(communities))\n",
    "    \n",
    "    color_map = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(communities)):\n",
    "        \n",
    "    \n",
    "        for node in graph4:\n",
    "            if node in node_groups[i]:\n",
    "\n",
    "                color_map.append((colors[i]))\n",
    "                \n",
    "    print(len(color_map))\n",
    "            \n",
    "    return(color_map)\n",
    "    \n",
    "\n",
    "color_map = color_mapping (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add pos = pos argument to make graph look nicer\n",
    "\n",
    "plt.figure(figsize = (50,50) )\n",
    "nx.draw(graph4, node_color=color_map,  with_labels = False, node_size = 10)   # can remove node_color = color_map to get rid of colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74390f8f",
   "metadata": {},
   "source": [
    "## Build a dataframe with id, text, and community which tweet belongs too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3984c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets\n",
    "\n",
    "print((clean_tweets.shape))\n",
    "\n",
    "clean_tweets1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4list = list(graph4)\n",
    "\n",
    "print(len(graph4list))\n",
    "\n",
    "graph4list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fcd62",
   "metadata": {},
   "source": [
    "Not all the tweets are included in the network so need to remove the tweets which are not in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets1[clean_tweets1['id'].isin(graph4list)]\n",
    "\n",
    "print(len(clean_tweets1))\n",
    "\n",
    "clean_tweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d294bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(communities)):\n",
    "    #print(j)\n",
    "    \n",
    "    for k in communities[i]:\n",
    "        \n",
    "        a = (k,i)\n",
    "        \n",
    "        empty.append(a)\n",
    "        \n",
    "empty\n",
    "\n",
    "\n",
    "\n",
    "coms = pd.DataFrame(empty, columns = ['id_1', 'community'])\n",
    "\n",
    "coms.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34effa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms['community'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28148a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_df = pd.merge(clean_tweets1, coms, left_on = clean_tweets1['id'], right_on = coms['id_1'])\n",
    "\n",
    "coms_df.drop(columns = ['key_0'], inplace = True)\n",
    "\n",
    "coms_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c84202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coms_filter (n):\n",
    "    \n",
    "    df = coms_df\n",
    "    \n",
    "    df = df.loc[df['community'] == n ] \n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_0 = coms_filter(0)\n",
    "\n",
    "coms_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc7df4",
   "metadata": {},
   "source": [
    "## Make wordclouds for the 4 largest communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe31fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def filter_small_coms (n):\n",
    "    \n",
    "#    min_repeat = n \n",
    "    \n",
    "#    vc = coms_df['community'].value_counts()\n",
    "    \n",
    "#    coms_df1 = coms_df[coms_df['community'].isin(vc[vc > min_repeat].index)]\n",
    "    \n",
    "#    return(coms_df1)\n",
    "\n",
    "\n",
    "#coms_df1 = filter_small_coms (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = list(STOPWORDS)\n",
    "\n",
    "#new_stops = ['new', 'year', 'amp', 's', 't', 'u', 'young', 'youngkin']\n",
    "\n",
    "stopwords1.extend(['new', 'year', 'amp', 's', 't', 'u', 'young', 'youngkin', 'dont', 'know', 'people' ,'better'\n",
    "                  'new', 'year', 'amp', 's', 't', 'u', 'young', 'youngkin', 'dont', 'know', 'people' ,'better', \n",
    "                   'need', 'big', 'day', 'school', 'help', 'back', 'don', 'real', 'going', 'way', 'ye', 'lot', \n",
    "                  'vegan', 'yes' 'time' , 'love', 're', 'thank', 'read', 'share', 'one', 'wow', 'please', 'yes',\n",
    "                  'care', 'come', 'really', 'much', 'beautiful', 'shit', 've', 'think', 'really', 'right', 'tried',\n",
    "                  'modern', 'exactly', 'take', 'time', 'build', 'make', 'article', 'human', 'say'])\n",
    "\n",
    "\n",
    "stopwords1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5828d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to build the wordcloud\n",
    "\n",
    "def make_cloud(n):\n",
    "    \n",
    "    coms = coms_filter(n)\n",
    "    \n",
    "    text = \" \".join(review for review in coms.clean_text.astype(str))\n",
    "    \n",
    "    wordcloud = WordCloud(width = 3000, \n",
    "                          height = 2000, \n",
    "                          random_state=1, \n",
    "                          background_color='black', \n",
    "                          colormap='Set2', \n",
    "                          collocations=False, \n",
    "                          stopwords = stopwords1).generate(text)\n",
    "    \n",
    "    return(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to plot the actual wordclouds\n",
    "\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d352e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function selects the n largest communities from the network\n",
    "\n",
    "def n_largest_coms (n):\n",
    "    \n",
    "    a = coms_df['community'].value_counts(ascending = False).head(n)\n",
    "    \n",
    "    a = pd.DataFrame(a)\n",
    "    \n",
    "    largest_coms = list(a.index)\n",
    "    \n",
    "    df=coms_df[coms_df['community'].isin(largest_coms)]\n",
    "    \n",
    "    print(df['community'].unique())\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "coms_df1 = n_largest_coms(4)\n",
    "\n",
    "coms_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = coms_df['community'].value_counts(ascending = False).head(4)\n",
    "                                                             \n",
    "a = pd.DataFrame(a)\n",
    "\n",
    "a\n",
    "                                                             \n",
    "largest_coms = list(a.index)\n",
    "\n",
    "df=coms_df[coms_df['community'].isin(largest_coms)]\n",
    "                                                             \n",
    "                                                             \n",
    "df\n",
    "\n",
    "print(df['community'].unique())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_coms = list(coms_df1['community'].unique())\n",
    "\n",
    "large_coms.sort()  \n",
    "\n",
    "large_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306c55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbe9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = []\n",
    "\n",
    "for i,j in enumerate(large_coms):\n",
    "    \n",
    "    mid = 'wordcloud for community '  + str(j) + \"\\n Number of tweets in comminity \" + str(j) + ' is ' + str(len(communities[j]))\n",
    "    \n",
    "    #print(\"wordcloud_\" + str(i))\n",
    "    \n",
    "    #empty.append(\"wordcloud_\" + str(i))\n",
    "    \n",
    "    captions.append(mid)\n",
    "    \n",
    "        \n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = []\n",
    "\n",
    "for i in large_coms:\n",
    "    print(i)\n",
    "    \n",
    "    cloud = \"wordcloud_\" + str(i)\n",
    "    \n",
    "    print(cloud)\n",
    "    \n",
    "    cloud = make_cloud(i)\n",
    "    \n",
    "    clouds.append(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############# do notttttt runnnnnnnnnnnn \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rows = 2\n",
    "columns = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(len(clouds)):\n",
    "    \n",
    "    fig.add_subplot(rows, columns, (i+1))\n",
    "\n",
    "    plt.imshow(clouds[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(captions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2\n",
    "columns = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(len(clouds)):\n",
    "    \n",
    "    fig.add_subplot(rows, columns, (i+1))\n",
    "\n",
    "    plt.imshow(clouds[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(captions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43206acd",
   "metadata": {},
   "source": [
    "## jaccard index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = cleaner(tweets)\n",
    "clean_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_combinations (df):\n",
    "    \n",
    "    df['key'] = 0\n",
    "    \n",
    "    df = df.merge(df, on = 'key', how = 'outer')\n",
    "    \n",
    "    df = df[['id_x', 'clean_text_x', 'id_y', 'clean_text_y']]\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "    return (df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d1cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_combs = tweets_combinations(clean_tweets)\n",
    "\n",
    "tweet_combs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10619a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    try:\n",
    "        z = float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    except ZeroDivisionError:\n",
    "        z = 0\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595813e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_index(df):\n",
    "    \n",
    "    df['jaccard'] = df.apply(lambda x: get_jaccard_sim(x['clean_text_x'], x['clean_text_y']), axis=1)\n",
    "    \n",
    "    df = df[(df['jaccard'] != 1) & (df['jaccard'] >= .15)]\n",
    "    \n",
    "    print(df.shape)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f56a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index_grid_search(df):\n",
    "    \n",
    "    # Calculate Jaccard Index and save it in a column\n",
    "    df['jaccard'] = df.apply(lambda x: get_jaccard_sim(x['clean_text_x'], x['clean_text_y']), axis=1)\n",
    "    df = df[df['jaccard'] != 1]\n",
    "    \n",
    "    # Find number of connections for differenct jaccard index threshold\n",
    "    index_connections = pd.DataFrame(columns = ['jaccard_threshold', 'connections'])\n",
    "    for i in np.arange(0.0, 1.0, 0.01):\n",
    "        df1 = df[tweet_combs['jaccard'] >= i]\n",
    "        index_connections = index_connections.append({'jaccard_threshold': i, 'connections': df1.shape[0]}, \n",
    "                                                     ignore_index=True)\n",
    "\n",
    "    return df, index_connections\n",
    "jaccard_tweets, index_connections = jaccard_index_grid_search(tweet_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c61b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index_connections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_connections = index_connections['connections'].tolist()\n",
    "\n",
    "connections_per_tweet = [i/(len(tweet_combs)) for i in idx_connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_per_tweet = [i/(len(tweet_combs)) for i in idx_connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connections_per_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daccc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = index_connections['jaccard_threshold'].tolist()\n",
    "\n",
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b987fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold, connections_per_tweet)\n",
    "\n",
    "plt.xticks(np.arange(0,1, step = 0.05))\n",
    "\n",
    "plt.xlabel('Jaccard threshold')\n",
    "\n",
    "plt.ylabel('Connections per node')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184d5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 11.7,8.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98950d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f78ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b27dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf2585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6658f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a8abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acaaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.histplot(jaccard_tweets, x = 'jaccard', bins = 100)\n",
    "\n",
    "plot.set(xlabel = 'Jaccard similarity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fee7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b815be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b552f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c801448",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ba16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = calculate_jaccard_index(tweet_combs)\n",
    "similarity\n",
    "\n",
    "\n",
    "#(13410, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65735a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph5 = nx.from_pandas_edgelist(similarity, source = \"id_x\", target = \"id_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5620518",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [node for node, degree in graph5.degree() if degree < 3]\n",
    "graph5.remove_nodes_from(remove)\n",
    "pos = nx.spring_layout(graph5, k=0.15, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42afd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph5 = nx.from_pandas_edgelist(similarity, source = \"id_x\", target = \"id_y\")\n",
    "\n",
    "plt.figure(figsize = (80,80) )\n",
    "nx.draw(graph5, pos = pos, with_labels = False, node_size = 1200)\n",
    "plt.savefig('/Users/max/Documents/Data science files/Diss images/network1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8cfac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "13410/35688676"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88f1ef",
   "metadata": {},
   "source": [
    "# community detection on Jaccard network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import networkx.algorithms.community as nx_comm\n",
    "\n",
    "from cdlib import algorithms\n",
    "\n",
    "import community \n",
    "\n",
    "from networkx.algorithms import community\n",
    "\n",
    "from cdlib import viz\n",
    "\n",
    "from cdlib import evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_louvain = algorithms.louvain(graph5, resolution=1., randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b52186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,len(coms_louvain.communities)):\n",
    "#    print(\"Size of community \" + str(i) + \" is : \" + str(len(coms_louvain.communities[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nx_comm.louvain_communities(graph5, seed=123)\n",
    "\n",
    "count = 0 \n",
    "\n",
    "for i in range(0,len(communities)):\n",
    "    \n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "    count = count + len(communities[i])\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c87022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = nx.spring_layout(graph5)\n",
    "viz.plot_network_clusters(graph5, coms_louvain, pos,  min_size = 8, figsize = (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed222b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(evaluation.newman_girvan_modularity(graph5, coms_louvain))\n",
    "print(evaluation.avg_distance(graph5, coms_louvain))\n",
    "print(evaluation.cut_ratio(graph5, coms_louvain))\n",
    "print(evaluation.average_internal_degree(graph5, coms_louvain))\n",
    "print(evaluation.conductance(graph5, coms_louvain))\n",
    "print(evaluation.internal_edge_density(graph5, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a675564",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.avg_distance(graph5, coms_louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.cut_ratio(graph5, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.average_internal_degree(graph5, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.conductance(graph5, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04027f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.internal_edge_density(graph5, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee3909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f45fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350c09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fa1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e94092",
   "metadata": {},
   "source": [
    "## other method for community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# communities = nx_comm.louvain_communities(graph5, seed=123)\n",
    "\n",
    "# count = 0 \n",
    "\n",
    "# for i in range(0,len(communities)):\n",
    "    \n",
    "#     print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "#     count = count + len(communities[i])\n",
    "    \n",
    "# print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acedfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "\n",
    "# b = []\n",
    "# for i in range(len(communities)):\n",
    "#     a = len(communities[i])\n",
    "    \n",
    "#     if a < 5:\n",
    "#         print(a, i)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         b.append(communities[i])\n",
    "        \n",
    "#     count = count + a\n",
    "    \n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty = [] \n",
    "\n",
    "# for i in range(len(communities)):\n",
    "    \n",
    "    \n",
    "#     length = len(communities[i])\n",
    "    \n",
    "       \n",
    "    \n",
    "#     if length < 5:\n",
    "        \n",
    "#         empty.append(communities[i])\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# count = 0\n",
    "\n",
    "# for i in empty:\n",
    "#     count = count + len(i)\n",
    "    \n",
    "    \n",
    "# count    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# small_coms_ids = []\n",
    "\n",
    "# for i in empty:\n",
    "#     for j in i:\n",
    "        \n",
    "        \n",
    "#         small_coms_ids.append(j)\n",
    "        \n",
    "        \n",
    "# graph5.remove_nodes_from(small_coms_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64936197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# node_groups = []\n",
    "# for com in communities:\n",
    "#     node_groups.append(list(com))\n",
    "\n",
    "\n",
    "\n",
    "# def color_mapping_0 ():\n",
    "    \n",
    "\n",
    "\n",
    "#     color_map0 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for node in graph5:  ### graph goes here, argument for func is graph5\n",
    "#         if node in node_groups[0]:\n",
    "#             color_map0.append(('blue', node))\n",
    "\n",
    "#         if node in node_groups[1]:\n",
    "#             color_map0.append(('green',node))   \n",
    "\n",
    "#         if node in node_groups[2]:\n",
    "#             color_map0.append(('red',node))\n",
    "\n",
    "#         if node in node_groups[3]:\n",
    "#             color_map0.append(('cyan',node))\n",
    "\n",
    "#         if node in node_groups[4]:\n",
    "#             color_map0.append(('magenta',node))\n",
    "\n",
    "#         if node in node_groups[5]:\n",
    "#             color_map0.append(('yellow',node))  \n",
    "\n",
    "\n",
    "#         if node in node_groups[6]:\n",
    "#             color_map0.append(('magenta',node))\n",
    "\n",
    "#         if node in node_groups[7]:\n",
    "#             color_map0.append(('yellow',node))\n",
    "\n",
    "#         if node in node_groups[8]:\n",
    "#             color_map0.append(('black',node))\n",
    "\n",
    "\n",
    "#         if node in node_groups[9]:\n",
    "#             color_map0.append(('white',node))\n",
    "\n",
    "#         if node in node_groups[10]:\n",
    "#             color_map0.append(('#0A8F19',node))\n",
    "        \n",
    "        \n",
    "#         if node in node_groups[11]:\n",
    "#             color_map0.append(('#9483FE',node))\n",
    "            \n",
    "            \n",
    "#     new_map = []\n",
    "\n",
    "\n",
    "#     for i in range(len(color_map0)):\n",
    "\n",
    "#         new_map.append(color_map0[i][0])  \n",
    "            \n",
    "            \n",
    "#     print(len(new_map))\n",
    "            \n",
    "        \n",
    "#     return(new_map)\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb159b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_map0 = color_mapping_0 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc336eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def colour_generator (num_colors):\n",
    "    \n",
    "#     number_of_colors = num_colors\n",
    "    \n",
    "#     color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "#              for i in range(number_of_colors)]\n",
    "    \n",
    "#     return(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60bc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_groups = []\n",
    "# for com in communities:\n",
    "#     node_groups.append(list(com))\n",
    "\n",
    "\n",
    "\n",
    "# def color_mapping (communities):\n",
    "    \n",
    "#     colors = colour_generator (len(communities))\n",
    "    \n",
    "#     color_map = []\n",
    "    \n",
    "    \n",
    "#     for i in range(len(communities)):\n",
    "        \n",
    "    \n",
    "#         for node in graph5:\n",
    "#             if node in node_groups[i]:\n",
    "\n",
    "#                 color_map.append((colors[i]))\n",
    "                \n",
    "#     print(len(color_map))\n",
    "            \n",
    "#     return(color_map)\n",
    "    \n",
    "\n",
    "# color_map = color_mapping (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af508f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_map = color_mapping (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c10803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (50,50) )\n",
    "#nx.draw(graph5, node_color=new_map,  with_labels = False, node_size = 10)   # can remove node_color = color_map to get rid of colors\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (50,50) )\n",
    "# nx.draw(graph5, node_color=color_map,  with_labels = False, node_size = 30)   # can remove node_color = color_map to get rid of colors\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b13ba",
   "metadata": {},
   "source": [
    "## Build a dataframe with id, text, and community which tweet belongs too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets\n",
    "\n",
    "print(len(clean_tweets))\n",
    "\n",
    "clean_tweets1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph5list = list(graph5)\n",
    "\n",
    "print(len(graph5list))\n",
    "\n",
    "graph5list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad377d2",
   "metadata": {},
   "source": [
    "Can see that the length of the graph is less than the length of the dataframe of all tweets as not all the tweets were added to the network, so need to remove the tweets from the df that were not in the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716083bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets1[clean_tweets1['id'].isin(graph5list)]\n",
    "\n",
    "print(len(clean_tweets1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(communities)):\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in communities[i]:\n",
    "        a = (k,i)\n",
    "    \n",
    "    \n",
    "        empty.append(a)\n",
    "        \n",
    "empty\n",
    "\n",
    "\n",
    "coms = pd.DataFrame(empty, columns = ['id_1', 'community'])\n",
    "\n",
    "coms.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb939e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_df = pd.merge(clean_tweets1, coms, left_on = clean_tweets1['id'], right_on = coms['id_1'])\n",
    "\n",
    "coms_df.drop(columns = ['key_0'], inplace = True)\n",
    "\n",
    "print(coms_df.shape)\n",
    "\n",
    "coms_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfcc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coms_filter (n):\n",
    "    \n",
    "    df = coms_df\n",
    "    \n",
    "    df = df.loc[df['community'] == n ]\n",
    "   \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = coms_filter(6)\n",
    "\n",
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2587e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_length = coms_df['community'].value_counts()\n",
    "\n",
    "com_length\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c224735",
   "metadata": {},
   "source": [
    "## Make wordclouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66494ed3",
   "metadata": {},
   "source": [
    "First get rid of the very small communities, then make wordcloud for communities with more than 1000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02615c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = list(STOPWORDS)\n",
    "\n",
    "stopwords1.extend(['rt', 'amp', 't', 's', 'let', 'nothing', 'auroraakeira', 'great', 'us'])\n",
    "\n",
    "stopwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cec6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cloud(n):\n",
    "    \n",
    "    coms = coms_filter(n)\n",
    "    \n",
    "    text = \" \".join(review for review in coms.clean_text.astype(str))\n",
    "    \n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = stopwords1).generate(text)\n",
    "    \n",
    "    return(wordcloud)\n",
    "\n",
    "    #plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c173d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_length = coms_df['community'].value_counts()\n",
    "\n",
    "com_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function selects the n largest communities from the network\n",
    "\n",
    "def n_largest_coms (n):\n",
    "    \n",
    "    a = coms_df['community'].value_counts(ascending = False).head(n)\n",
    "    \n",
    "    a = pd.DataFrame(a)\n",
    "    \n",
    "    largest_coms = list(a.index)\n",
    "    \n",
    "    df=coms_df[coms_df['community'].isin(largest_coms)]\n",
    "    \n",
    "    print(df['community'].unique())\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "coms_df1 = n_largest_coms(4)\n",
    "\n",
    "coms_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coms_df1.shape)\n",
    "\n",
    "coms_df1.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_df1['community'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99016a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_coms = list(coms_df1['community'].unique())\n",
    "\n",
    "large_coms.sort()\n",
    "large_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = []\n",
    "\n",
    "#for i in range(10):\n",
    "\n",
    "for i,j in enumerate(large_coms):\n",
    "    \n",
    "    mid = 'wordcloud for community '  + str(j) + \"\\n Number of tweets in comminity \" + str(j) + ' is ' + str(len(communities[j]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"wordcloud_\" + str(i))\n",
    "    \n",
    "    #empty.append(\"wordcloud_\" + str(i))\n",
    "        \n",
    "    captions.append(mid)\n",
    "\n",
    "        \n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = []\n",
    "\n",
    "for i in large_coms:\n",
    "    print(i)\n",
    "    \n",
    "    cloud = \"wordcloud_\" + str(i)\n",
    "    \n",
    "    print('cloud part 1', cloud)\n",
    "    \n",
    "    cloud = make_cloud(i)\n",
    "    \n",
    "    print('cloud part 2', cloud)\n",
    "    \n",
    "    clouds.append(cloud)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100db569",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2\n",
    "columns = 2\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(len(clouds)):\n",
    "    \n",
    "    fig.add_subplot(rows, columns, (i+1))\n",
    "    \n",
    "    plt.imshow(clouds[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(captions[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d3d72",
   "metadata": {},
   "source": [
    "# Building a network using a Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = cleaner(tweets)\n",
    "\n",
    "\n",
    "\n",
    "clean_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38160e8c",
   "metadata": {},
   "source": [
    "## new code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564ade6",
   "metadata": {},
   "source": [
    "# code using similarity matrix from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb531d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets\n",
    "\n",
    "print(clean_tweets1.shape)\n",
    "\n",
    "clean_tweets1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ecdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentance = clean_tweets1['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ddeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_embeddings = model.encode(sentance)\n",
    "sen_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a725e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cosine_similarity(sen_embeddings)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### make sure to re run this code every time so that the lists dont double fill\n",
    "\n",
    "\n",
    "c = clean_tweets['id'].tolist()  \n",
    "h = []\n",
    "v = []\n",
    "w = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7674ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    \n",
    "    for j in range(a.shape[1]):\n",
    "        if a[i][j] > 0.72 and a[i][j] < 0.99:\n",
    "            h.append(c[i])\n",
    "            v.append(c[j])\n",
    "            w.append(a[i][j])\n",
    "        if i == j:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31dae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = pd.DataFrame({'id_x': h, 'id_y': v, 'similarity': w})\n",
    "\n",
    "\n",
    "edge = edge[(edge['similarity'] < 0.99)]\n",
    "\n",
    "edge\n",
    "\n",
    "edge.reset_index(inplace=True)\n",
    "\n",
    "edge.drop(['index'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# using stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "455471/35682514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_combinations (df):\n",
    "    \n",
    "    df['key'] = 0\n",
    "    \n",
    "    df = df.merge(df, on = 'key', how = 'outer')\n",
    "    \n",
    "    df = df[['id_x', 'clean_text_x', 'id_y', 'clean_text_y']]\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "    return (df)    \n",
    "\n",
    "\n",
    "tweet_combs = tweets_combinations(clean_tweets)\n",
    "\n",
    "#tweet_combs['source'] = edge['source']\n",
    "\n",
    "#tweet_combs['target'] = edge['target']\n",
    "\n",
    "tweet_combs['similarity'] = edge['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index_grid_search(df):\n",
    "    \n",
    "    # Calculate Jaccard Index and save it in a column\n",
    "    \n",
    "    \n",
    "    # Find number of connections for differenct jaccard index threshold\n",
    "    index_connections = pd.DataFrame(columns = ['jaccard_threshold', 'connections'])\n",
    "    for i in np.arange(0.0, 1.0, 0.01):\n",
    "        df1 = df[tweet_combs['similarity'] >= i]\n",
    "        index_connections = index_connections.append({'jaccard_threshold': i, 'connections': df1.shape[0]}, \n",
    "                                                     ignore_index=True)\n",
    "\n",
    "    return df, index_connections\n",
    "jaccard_tweets, index_connections = jaccard_index_grid_search(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee73ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b26835",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_connections = index_connections['connections'].tolist()\n",
    "\n",
    "connections_per_tweet = [i/(len(tweet_combs)) for i in idx_connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = index_connections['jaccard_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshold, connections_per_tweet)\n",
    "\n",
    "plt.xticks(np.arange(0,1, step = 0.05))\n",
    "\n",
    "plt.xlabel('Cosine threshold')\n",
    "\n",
    "plt.ylabel('Connections per node')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.histplot(jaccard_tweets, x = 'similarity', bins = 100)\n",
    "\n",
    "plot.set(xlabel = 'similarity')\n",
    "\n",
    "plot.set(xlim=(0, None))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab5d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36c901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faeddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1241caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph6 = nx.from_pandas_edgelist(edge, source = \"id_x\", target = \"id_y\") # source and target or id_x and id_y\n",
    "\n",
    "remove = [node for node, degree in graph6.degree() if degree < 5]\n",
    "graph6.remove_nodes_from(remove)\n",
    "pos = nx.spring_layout(graph6, k=0.15, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ad555",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph6)\n",
    "\n",
    "# 5893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,50) )\n",
    "nx.draw(graph6, pos, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54b8a0",
   "metadata": {},
   "source": [
    "## community detection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b09fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph6.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph6.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_louvain = algorithms.louvain(graph6, resolution=1., randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(coms_louvain.communities)):\n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(coms_louvain.communities[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9649fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(graph6)\n",
    "\n",
    "viz.plot_network_clusters(graph6, coms_louvain, pos, min_size = 8, figsize = (50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.newman_girvan_modularity(graph6, coms_louvain))\n",
    "print(evaluation.avg_distance(graph6, coms_louvain))\n",
    "print(evaluation.cut_ratio(graph6, coms_louvain))\n",
    "print(evaluation.average_internal_degree(graph6, coms_louvain))\n",
    "print(evaluation.conductance(graph6, coms_louvain))\n",
    "print(evaluation.internal_edge_density(graph6, coms_louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = coms_louvain.communities\n",
    "\n",
    "communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c7cbc",
   "metadata": {},
   "source": [
    "## Actual method from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nx_comm.louvain_communities(graph6, seed=123)\n",
    "\n",
    "communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f610a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(0,len(communities)):\n",
    "    print(\"Size of community \" + str(i) + \" is : \" + str(len(communities[i])))\n",
    "    \n",
    "    count = count + len(communities[i])\n",
    "    \n",
    "    \n",
    "print('Total num of tweets in all communities is :', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generates n random colors\n",
    "\n",
    "# def colour_generator (num_colors):\n",
    "    \n",
    "#     number_of_colors = num_colors\n",
    "    \n",
    "#     color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "#              for i in range(number_of_colors)]\n",
    "    \n",
    "#     return(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ec965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['blue', 'green', 'red', 'magenta', 'cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block of code generates the color map so that each node has a color corresponding to its community\n",
    "\n",
    "\n",
    "\n",
    "# node_groups = []\n",
    "# for com in communities:\n",
    "#     node_groups.append(list(com))\n",
    "\n",
    "# def color_mapping (communities):\n",
    "    \n",
    "#     #colors = colour_generator (len(communities))\n",
    "    \n",
    "#     color_map = []\n",
    "    \n",
    "    \n",
    "#     for i in range(len(communities)):\n",
    "        \n",
    "    \n",
    "#         for node in graph6:\n",
    "#             if node in node_groups[i]:\n",
    "\n",
    "#                 color_map.append((colors[i]))\n",
    "                \n",
    "#     print(len(color_map))\n",
    "            \n",
    "#     return(color_map)\n",
    "    \n",
    "\n",
    "# color_map = color_mapping (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(graph6, k = 0.15, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,50) )\n",
    "nx.draw(graph6, pos = pos, node_color=color_map,  with_labels = False, node_size = 10)   # can remove node_color = color_map to get rid of colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e762771",
   "metadata": {},
   "source": [
    "## build a dataframe with tweet id, text, and community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = coms_louvain.communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets\n",
    "\n",
    "print(clean_tweets.shape)\n",
    "\n",
    "clean_tweets1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph6list = list(graph6)\n",
    "\n",
    "print(len(graph6list))\n",
    "\n",
    "graph6list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = clean_tweets1[clean_tweets1['id'].isin(graph6list)]\n",
    "\n",
    "print(len(clean_tweets1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(communities)):\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in communities[i]:\n",
    "        a = (k,i)\n",
    "    \n",
    "    \n",
    "        empty.append(a)\n",
    "        \n",
    "empty\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "coms = pd.DataFrame(empty, columns = ['id_1', 'community'])\n",
    "\n",
    "\n",
    "coms.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coms['community'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_df = pd.merge(clean_tweets1, coms, left_on = clean_tweets1['id'], right_on = coms['id_1'])\n",
    "\n",
    "coms_df.drop(columns = ['key_0'], inplace = True)\n",
    "\n",
    "coms_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce66194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coms_filter (n):\n",
    "    \n",
    "    df = coms_df\n",
    "    \n",
    "    df = df.loc[df['community'] == n ] \n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850c217",
   "metadata": {},
   "source": [
    "## Build wordcloud for 4 largest communities within bert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = list(STOPWORDS)\n",
    "\n",
    "#new_stops = ['new', 'year', 'amp', 's', 't', 'u']\n",
    "\n",
    "stopwords1.extend(['new', 'year', 'amp', 's', 't', 'u', 'thank', 'love' 'new', 'say', 'happy', 'well',\n",
    "                   'year', 'amp', 's', 't', 'u', 'thank', 'love', 'let', 'right', 'go', 'one', 'time',\n",
    "                  'well', 'day', 'happy', 'well', 'day', 'us', 'think', 'want', 'please', 'well', 'help',\n",
    "                  'last', 'know', 'back', 'good', 'great', 'going', 'still', 'many', 'make', 'see', 're',\n",
    "                  'halloween', 'much', 'need', 'work', 'today', 'really', 'take', 'media', 'live', 'people',\n",
    "                  'halloween', 'years', 'month', 'private', 'first', 'days', 'week', 'month', 'friend', 'brandon',\n",
    "                  'better', 'real', 'best', 'hope', 'november', 'thing', 'm', 'psaki', 'joe', 'true', 'beautiful',\n",
    "                   'every', 'thanks' ])\n",
    "\n",
    "stopwords1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to build the wordcloud\n",
    "\n",
    "def make_cloud(n):\n",
    "    \n",
    "    coms = coms_filter(n)\n",
    "    \n",
    "    text = \" \".join(review for review in coms.clean_text.astype(str))\n",
    "    \n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = stopwords1).generate(text)\n",
    "    \n",
    "    return(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to plot the actual wordclouds\n",
    "\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee048edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_largest_coms (n):\n",
    "    \n",
    "    \n",
    "    a = coms_df['community'].value_counts(ascending = False).head(n)\n",
    " \n",
    "    a = pd.DataFrame(a)\n",
    "    \n",
    "    largest_coms = list(a.index)\n",
    "    \n",
    "    df=coms_df[coms_df['community'].isin(largest_coms)]\n",
    "    \n",
    "    print(df['community'].unique())\n",
    "    \n",
    "    return(df)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "coms_df1 = n_largest_coms(4)\n",
    "\n",
    "coms_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d31b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_coms = list(coms_df1['community'].unique())\n",
    "\n",
    "large_coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bda6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = []\n",
    "\n",
    "for i,j in enumerate(large_coms):\n",
    "    \n",
    "    mid = 'wordcloud for community '  + str(j) + \"\\n Number of tweets in comminity \" + str(j) + ' is ' + str(len(communities[j]))\n",
    "    \n",
    "    #print(\"wordcloud_\" + str(i))\n",
    "    \n",
    "    #empty.append(\"wordcloud_\" + str(i))\n",
    "        \n",
    "    captions.append(mid)\n",
    "\n",
    "        \n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = []\n",
    "\n",
    "for i in large_coms:\n",
    "    print(i)\n",
    "    \n",
    "    cloud = \"wordcloud_\" + str(i)\n",
    "    \n",
    "    print( cloud)\n",
    "    \n",
    "    cloud = make_cloud(i)\n",
    "    \n",
    "    clouds.append(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb03354",
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2\n",
    "columns = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(len(clouds)):\n",
    "        \n",
    "    \n",
    "    \n",
    "    fig.add_subplot(rows, columns, (i+1))\n",
    "    \n",
    "    plt.imshow(clouds[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(captions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b7bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f366ae",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10507fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b994da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1 = cleaner(tweets)\n",
    "\n",
    "clean_tweets1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "stop\n",
    "\n",
    "stop.extend(['rt', 'amp', 't', 's', 'go', 'get', 'people', 'food', 'ass', 'tweet', 'dozen', 'believe', 'day', 'candy',\n",
    "            'food' 'vet', 'till', 'kid', 'know', 'first', 'say', 'person', 'home', 'place', 'take', 'time', 'good', 've', 'take', 'time',\n",
    "            'see', 'let', 'matter', 'help', 'delete', 'lose', 'life', 'hope', 'friend', 'man', 'food', 'head', 'bad'\n",
    "            ,'go', 'need', 'want', 're'' tell' , 'say', 'well', 'use', 'right', 'get', 'think', 'year', 'say', 'get', 'still', 'go', 'tell', \n",
    "             're', 'today'  , 'go', 'get', 'say', 're', 'make', 'year', 've', 'new', 'give', 'world' 'child', 'go' , 'funds', 're', 'much',\n",
    "             'love', 'many', 'way', 'back', 'also', 'understand', 'call', 'look' , 'last', 'pay', 'run', 'thing', 'case', 'leave', 'ask', 'eat',\n",
    "             'keep', 'th', 'month', 'message', 'less', 'try', 'show', 'lead', 'medium', 'never', 'find', 'flight', 've', 'halloween', 'come', 'long', \n",
    "             'watch', 'meet', 'actually', 'th', 'great', 'work', 'report', 'stop', 'question', 'work', 'report', 'even', 'fight' 've' 'th',\n",
    "             'really', 'lot', 'possible', 'guy', 'contine', 'live', 'happy', 'parent', 'job', 'read', 'share', 'team', 'move', 'late', 'video',\n",
    "             'live', 'elite', 'start', 'ever', 'fact', 'one', 'wear', 'daily', 'child', 'high', 'woman', 'stand', 'happen', 'next', 'plan',\n",
    "             'opportunity', 'th', 'break', 'care', 'course', 'idea', 'support', 'shit', 'thank', 'change', 'problem', 'enough', 'hard', \n",
    "             'exactly', 'costume', 'absoloutley', 'big', 'point', 'half', 'continue', 'become', 'always', 'animal', 'full', 'else', 'wish',\n",
    "             'put', 'speak', 'sure', 'hand', 'dog', 'play', 'story', 'vegan', 'voting', 'water', 'dr', 'night', 'death', 'game', 'money',\n",
    "             'word', 'week', 'lol', 'sex', 'th', 'pm', 'book', 'water', 'part', 'number', 'st', 'heart', 'post', 'monday', 'health', \n",
    "             'truth', 'un', 'november', 'twitter', 'age', 'nut', 'bank', 'jaskposobiec', 'tuesday', 'jan', 'pilot', 'member', 'reminder'            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "clean_tweets1['clean_text'] = clean_tweets1['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = clean_tweets1['clean_text'].tolist()\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44387f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = []\n",
    "for i in range(len(texts)):\n",
    "    types.append(type(str(texts[i])))\n",
    "    \n",
    "set(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2465b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets1['clean_text'] = clean_tweets1['clean_text'].astype(str)\n",
    "\n",
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e139a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# texts = clean_tweets1['clean_text1'].tolist()\n",
    "\n",
    "# def gen_words(words):\n",
    "        \n",
    "#     final = []\n",
    "         \n",
    "#     for text in texts:\n",
    "         \n",
    "#         #lemmatizer = WordNetLemmatizer()\n",
    "         \n",
    "#         #text1 = lemmatizer.lemmatize(text)\n",
    "         \n",
    "#         new = gensim.utils.simple_preprocess(text, deacc = True)\n",
    "        \n",
    "#         print(new)\n",
    "        \n",
    "#         final.append(new)\n",
    "         \n",
    "#     return(final)\n",
    "\n",
    "# data = gen_words(texts)\n",
    "\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9787cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\", 'PROPN']): # allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                #new_text.append(token)\n",
    "                new_text.append(token.lemma_)\n",
    "                \n",
    "                \n",
    "        \n",
    "                #print(new_text)\n",
    "           \n",
    "        \n",
    "                    \n",
    "        final = \" \".join(new_text)\n",
    "        \n",
    "        \n",
    "        texts_out.append(final)\n",
    "        \n",
    "        \n",
    "    return (texts_out)\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(clean_tweets1['clean_text'])\n",
    "print (lemmatized_texts[0][0:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### this block of code ensures any stop words are removed after lemmatization\n",
    "\n",
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(lemmatized_texts)):\n",
    "    \n",
    "    text = lemmatized_texts[i]\n",
    "    \n",
    "    words = text.split() ## a list of the words \n",
    "    \n",
    "    new_text = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word not in stop:\n",
    "            \n",
    "            new_text.append(word)\n",
    "            \n",
    "           # print(new_text)\n",
    "            \n",
    "    final = \" \".join(new_text)\n",
    "    \n",
    "    final = final.replace(\"\", \"\")\n",
    "    \n",
    "    \n",
    "    final = final.translate(str.maketrans('', '', string.punctuation))    \n",
    "            \n",
    "    empty.append(final)\n",
    "        \n",
    "lemmatized_texts = empty  \n",
    "\n",
    "lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64947d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(lemmatized_texts)):\n",
    "    \n",
    "    text = lemmatized_texts[i]\n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    new_text = []\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        word = word.replace(\"\", \"\")\n",
    "        \n",
    "        word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    \n",
    "        if word not in stop:\n",
    "            \n",
    "            new_text.append(word)\n",
    "            \n",
    "           # print(new_text)\n",
    "            \n",
    "    final = \" \".join(new_text)\n",
    "    \n",
    "    final = final.replace(\"\", \"\")\n",
    "    \n",
    "    \n",
    "    final = final.translate(str.maketrans('', '', string.punctuation))    \n",
    "            \n",
    "    empty.append(final)\n",
    "        \n",
    "lemmatized_texts = empty  \n",
    "\n",
    "lemmatized_texts\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = []\n",
    "\n",
    "\n",
    "for i in range(len(lemmatized_texts)):\n",
    "    \n",
    "    text = lemmatized_texts[i]\n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    new_text = []\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f036d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9f660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec39e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2578c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "\n",
    "print (data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words], threshold=50)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram[doc] for doc in texts]\n",
    "\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram[bigram[doc]] for doc in texts]\n",
    "\n",
    "data_bigrams = make_bigrams(data_words)\n",
    "\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "\n",
    "print(data_bigrams_trigrams[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278fd59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf = TfidfModel(corpus, id2word = id2word)\n",
    "\n",
    "# low_value = 0.8 \n",
    "\n",
    "# words = []\n",
    "\n",
    "# words_missing_in_tfidf = []\n",
    "\n",
    "# for i in range(0, len(corpus)):\n",
    "    \n",
    "#     bow = corpus[i]\n",
    "    \n",
    "#     low_value_words = []\n",
    "    \n",
    "#     tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    \n",
    "#     bow_ids = [id for id, value in bow]\n",
    "    \n",
    "#     low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    \n",
    "#     drops = low_value_words + words_missing_in_tfidf\n",
    "    \n",
    "#     for item in drops:\n",
    "        \n",
    "#         words.append(id2word[item])\n",
    "        \n",
    "#     words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "    \n",
    "#     new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    \n",
    "#     corpus[i] = new_bow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3,\n",
    "                                           random_state=123,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b81b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=2, num_words=30):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5db3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29297719",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'output_filename.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e119941",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90216127",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e447320",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae798c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777862f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
